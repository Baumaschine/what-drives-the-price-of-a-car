{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb228886",
   "metadata": {},
   "source": [
    "What drives the price of a car?\n",
    "\n",
    "Business Understanding:\n",
    "\n",
    "Business Perspective: Our mission is to identify the crucial factors that influence the pricing of used cars. In the context of the CRISP-DM framework, we must translate this business challenge into a precise data task.\n",
    "\n",
    "Data Task Definition: Our primary objective is to leverage data to address the following questions:\n",
    "\n",
    "    Preference for Car Origin: Determine whether customers exhibit a preference for German or Japanese cars when purchasing used vehicles.\n",
    "    Color Preference: Analyze whether customers have a preference for black or grey cars.\n",
    "    Regional Spending Patterns: Identify whether customers in specific regions are inclined to spend more on used cars.\n",
    "    Seasonal Spending: Determine the time of the year when customers tend to spend more on used cars.\n",
    "\n",
    "In summary, our data-driven tasks revolve around:\n",
    "\n",
    "    Optimizing Inventory: Making informed decisions about the types of cars to stock.\n",
    "    Competitive Pricing: Setting competitive prices based on regional insights.\n",
    "    Targeted Marketing: Running targeted marketing campaigns during sales downturns.\n",
    "    Customer Behavior Modeling: Targeting potential buyers through data-driven models.\n",
    "\n",
    "Business Goals and KPIs Remain the Same:\n",
    "\n",
    "    Gain insights into customer buying behavior.\n",
    "    Achieve a 10% year-over-year increase in profit.\n",
    "    Reduce annual marketing costs by 10%.\n",
    "\n",
    "Data Understanding:\n",
    "\n",
    "After considering the business perspective, it's essential to acquaint ourselves with the dataset and identify potential data quality issues. Here are the steps we'll take to accomplish this:\n",
    "\n",
    "    Dataset Overview: Our dataset comprises 426,880 unique customers and contains 18 distinct columns.\n",
    "\n",
    "    User Attributes: These include unique customer identifiers, city names, and state of car sale.\n",
    "\n",
    "    Sales Price Attributes: This category features the price of used cars.\n",
    "\n",
    "    Car Attributes: This group encompasses various car-related information, such as the car's manufacturing year, manufacturer, model, condition, cylinders, fuel type, odometer reading, title status, transmission type, drive, size, type, and paint color.\n",
    "\n",
    "Data Quality Assessment:\n",
    "\n",
    "    The data in the \"Car attributes\" category contains missing values that need interpretation.\n",
    "    Specifically, there are missing values in columns such as \"year,\" \"manufacturer,\" \"model,\" \"condition,\" \"cylinders,\" \"fuel,\" \"odometer,\" \"title_status,\" \"transmission,\" \"VIN,\" \"drive,\" \"size,\" \"type,\" and \"paint_color.\"\n",
    "    The \"VIN\" column is unnecessary for interpreting car sales and can be safely dropped.\n",
    "\n",
    "Quality of the data\n",
    "\n",
    "The Car attributes data has NULL values and would require the missing data to be interpreted.\n",
    "\n",
    "    year 1205\n",
    "    manufacturer 17646\n",
    "    model 5277\n",
    "    condition 174104\n",
    "    cylinders 177678\n",
    "    fuel 3013\n",
    "    odometer 4400\n",
    "    title_status 8242\n",
    "    transmission 2556\n",
    "    VIN 161042\n",
    "    drive 130567\n",
    "    size 306361\n",
    "    type 92858\n",
    "    paint_color 130203\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49020424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from sklearn.linear_model import (BayesianRidge, Lasso, LassoCV,\n",
    "                                  LinearRegression, Ridge, RidgeCV)\n",
    "from sklearn.metrics import (mean_absolute_error, mean_squared_error,\n",
    "                             mean_squared_log_error, r2_score)\n",
    "from sklearn.model_selection import (GridSearchCV, KFold, StratifiedKFold,\n",
    "                                     cross_val_score, train_test_split)\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8ece4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/fabia/OneDrive/Desktop/vehicles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543f3cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae8c49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e856b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are \" + str(df.shape[0]) + \" rows and \" + str(df.shape[1]) + \" columns in Dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eab041",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(df.nsmallest(n=426000, columns=['price']), x=\"price\", nbins=20, title=\"Price histogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761a0cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['year'], bins=20, edgecolor='k')\n",
    "plt.title(\"Number of cars categorized on Year\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5252d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(df, x=\"manufacturer\", nbins=20, title=\"Number of cars categorized on Manufacturer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff472ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_50_models = df['model'].value_counts()[:50]\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(top_50_models.index, top_50_models.values, edgecolor='k')\n",
    "plt.title(\"Number of cars categorized on Model (Top 50 models)\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9efe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar plot for car condition\n",
    "plt.figure(figsize=(10, 6))\n",
    "df['condition'].value_counts().plot(kind='bar', edgecolor='k')\n",
    "plt.title(\"Number of cars categorized on Car Condition\")\n",
    "plt.xlabel(\"Car Condition\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe98737",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "df['cylinders'].value_counts().plot(kind='bar', edgecolor='k')\n",
    "plt.title(\"Number of Cars Categorized on Cylinders\")\n",
    "plt.xlabel(\"Cylinders\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db2dfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "df['fuel'].value_counts().plot(kind='bar', edgecolor='k')\n",
    "plt.title(\"Number of Cars Categorized on Fuel Type\")\n",
    "plt.xlabel(\"Fuel Type\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da613d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['odometer'], bins=500, edgecolor='k')\n",
    "plt.title(\"Odometer Histogram\")\n",
    "plt.xlabel(\"Odometer Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaea22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(df, x=\"title_status\", title=\"Number of cars categorized on Title status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2d03e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(df, x=\"transmission\", title=\"Number of cars categorized on Transmission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efe337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(df, x=\"drive\", title=\"Number of cars categorized on Drive type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb879f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(df, x=\"size\", title=\"Number of cars categorized on Size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ee7092",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(df, x=\"type\", title=\"Number of cars categorized on Type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a062be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(df, x=\"paint_color\", title=\"Number of cars categorized on Color\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdf3241",
   "metadata": {},
   "source": [
    "\n",
    "Observations\n",
    "\n",
    "    Many categorical columns have Nan values. We need to either fill them in or remove the rows altogather.\n",
    "    Some of columns have outliers. This needs to be fixed.\n",
    "    Target column 'Price' has outliers and needs fixing. Price column is skewed as well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144df9ad",
   "metadata": {},
   "source": [
    "\n",
    "Data Preparation\n",
    "\n",
    "After our initial exploration and fine tuning of the business understanding, it is time to construct our final dataset prior to modeling. Here, we want to make sure to handle any integrity issues and cleaning, the engineering of new features, any transformations that we believe should happen (scaling, logarithms, normalization, etc.), and general preparation for modeling with sklearn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281732b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = df.reindex(columns=[\n",
    "    'id', 'region', 'year',\n",
    "    'manufacturer', 'model', 'condition',\n",
    "    'cylinders', 'fuel', 'odometer',\n",
    "    'title_status', 'transmission',\n",
    "    'VIN', 'drive', 'size',\n",
    "    'type', 'paint_color', 'state', 'price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c9db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb532aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Below are number of Nan values in each column!\")\n",
    "cars.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710a97f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dropping ID and VIN since it does not affect car prices!\")\n",
    "print(\"Dropping state and region as this does not affect \"\n",
    "      \"car prices much when there is demand!\")\n",
    "cars = cars.drop(columns=['id', 'VIN', 'state', 'region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb063a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(cars.isnull())\n",
    "fig.update_layout(\n",
    "    title = \"Heatmap showing Nan values in each column\")\n",
    "fig.update_layout(barmode='group', bargap=0.30,bargroupgap=0.0)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72bf15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [\n",
    "    'year',\n",
    "    'odometer'\n",
    "]\n",
    "cat_features = [\n",
    "    'manufacturer',\n",
    "    'model',\n",
    "    'condition',\n",
    "    'cylinders',\n",
    "    'fuel',\n",
    "    'title_status',\n",
    "    'transmission',\n",
    "    'drive',\n",
    "    'size',\n",
    "    'type',\n",
    "    'paint_color'\n",
    "]\n",
    "print(f\"These are numerical features in dataset: {num_features}\")\n",
    "print(f\"These are categorical features in dataset: {cat_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5ffd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_imputer = cars.copy()\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "def encode(data):\n",
    "    nonulls = np.array(data.dropna())\n",
    "    impute_reshape = nonulls.reshape(-1,1)\n",
    "    impute_ordinal = encoder.fit_transform(impute_reshape)\n",
    "    data.loc[data.notnull()] = np.squeeze(impute_ordinal)\n",
    "    return data\n",
    "\n",
    "for i in tqdm(range(len(cat_features))):\n",
    "    encode(cars_imputer[cat_features[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fea3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    BayesianRidge(),\n",
    "    DecisionTreeRegressor(\n",
    "        max_features='sqrt',\n",
    "        random_state=0\n",
    "    ),\n",
    "    ExtraTreesRegressor(\n",
    "        n_estimators=10,\n",
    "        random_state=0\n",
    "    ),\n",
    "    KNeighborsRegressor(\n",
    "        n_neighbors=15\n",
    "    )\n",
    "]\n",
    "score = pd.DataFrame()\n",
    "for estimator in estimators:\n",
    "    print(f\"Estimating using {estimator.__class__.__name__} estimator!\")\n",
    "    imputer = IterativeImputer(estimator)\n",
    "    cars_impute = cars_imputer.copy()\n",
    "    for col in cars_imputer.columns:\n",
    "        impute_data=imputer.fit_transform(\n",
    "            cars_impute[col].values.reshape(-1,1)\n",
    "        )\n",
    "        impute_data=impute_data.astype('int64')\n",
    "        impute_data = pd.DataFrame(\n",
    "            np.ravel(impute_data)\n",
    "        )\n",
    "        cars_impute[col]=impute_data\n",
    "    X = cars_impute.iloc[:,:-1]\n",
    "    y = np.ravel(cars_impute.iloc[:,-1:])\n",
    "    score[estimator.__class__.__name__] = cross_val_score(\n",
    "        estimator,\n",
    "        X,\n",
    "        y,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        cv=6\n",
    "    )\n",
    "del cars_imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9de9518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE scores of each estimator for cv=6\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520748de",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "means = -score.mean()\n",
    "errors = score.std()\n",
    "means.plot.barh(xerr=errors, ax=ax)\n",
    "ax.set_title('MSE with Different Imputation Methods')\n",
    "ax.set_xlabel('MSE')\n",
    "ax.set_yticks(np.arange(means.shape[0]))\n",
    "ax.set_yticklabels(means.index.tolist())\n",
    "plt.tight_layout(pad=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004bb1d3",
   "metadata": {},
   "source": [
    "\n",
    "Above figure shows that Bayesian Ridge Imputer is best with lower MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d00e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nan values in Numerical features\n",
    "cars.isnull().sum()[num_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cf9f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_num = cars[num_features]\n",
    "\n",
    "# Using estimators[0] = BayesianRidge to fill Nan values in Numerical features.\n",
    "imputer_num = IterativeImputer(estimators[0])\n",
    "impute_data = imputer_num.fit_transform(cars_num)\n",
    "cars[num_features] = impute_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77ca77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values after filling\n",
    "cars.isnull().sum()[num_features]\n",
    "\n",
    "# Nan values in Categorical features\n",
    "cars.isnull().sum()[cat_features]\n",
    "\n",
    "# Using BayesianRidge imputer for categorical columns as well.\n",
    "cars_cat = cars[cat_features]\n",
    "encoder=preprocessing.LabelEncoder()\n",
    "\n",
    "for columns in cat_features:\n",
    "    encode(cars_cat[columns])\n",
    "    imputer = IterativeImputer(BayesianRidge())\n",
    "    impute_data = imputer.fit_transform(cars_cat[columns].values.reshape(-1, 1))\n",
    "    impute_data = impute_data.astype('int64')\n",
    "    impute_data = pd.DataFrame(impute_data)\n",
    "    impute_data = encoder.inverse_transform(impute_data.values.reshape(-1, 1))\n",
    "    cars_cat[columns]=impute_data\n",
    "cars[cat_features]=cars_cat    \n",
    "\n",
    "cars.isnull().sum()[cat_features]\n",
    "\n",
    "fig = px.imshow(cars.isnull())\n",
    "fig.update_layout(\n",
    "    title = \"Heatmap showing all Nan values are eliminated!\")\n",
    "fig.update_layout(barmode='group', bargap=0.30,bargroupgap=0.0)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283aafca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_range(arr: list, col: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Function to find outliers range for given Array and column\n",
    "    \"\"\"\n",
    "    x_values = sorted(arr[col].values.ravel())\n",
    "    q_25 = 25 / 100 * (len(x_values) + 1)\n",
    "    i_p = int(str(q_25).split(\".\")[0])\n",
    "    f_p = int(str(q_25).split(\".\")[1])\n",
    "    q1 = x_values[i_p] + f_p * (x_values[i_p + 1] - x_values[i_p])\n",
    "    q_75 = 75/100*(len(x_values)+1)\n",
    "    i_p = int(str(q_75).split(\".\")[0])\n",
    "    f_p = int(str(q_75).split(\".\")[1])\n",
    "    q3 = x_values[i_p] + f_p * (x_values[i_p + 1] - x_values[i_p])\n",
    "    iqr = q3 - q1\n",
    "    x_values_1 = q1 - 1.5 * iqr\n",
    "    x_values_2 = q3 + 1.5 * iqr\n",
    "    return (x_values_1, x_values_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d3b195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_price(df: pd.DataFrame) -> tuple:\n",
    "    \"\"\"\n",
    "    Function to find min and max price to remove outliers\n",
    "    \"\"\"\n",
    "    range_ = []\n",
    "    q1, q3 = (df['logprice'].quantile([0.25,0.75]))\n",
    "    range_.append(q1 - 1.5 * (q3 - q1))\n",
    "    range_.append(q3 + 1.5 * (q3 - q1))\n",
    "    return (range_)\n",
    "\n",
    "# Adding logprice since price column is skewed. This brings normal distribution to price column.\n",
    "cars['logprice'] = np.log(cars['price'])\n",
    "x = cars['logprice']\n",
    "price_range = list(range(0, int(max(cars['logprice'])) + 1))\n",
    "red_square = dict(markerfacecolor='g', marker='s')\n",
    "plt.boxplot(x, vert=False)\n",
    "plt.xticks(price_range)\n",
    "plt.text(min_max_price(cars)[0]-0.3,1.05,str(round(min_max_price(cars)[0],2)))\n",
    "plt.text(min_max_price(cars)[1]-0.5,1.05,str(round(min_max_price(cars)[1],2)))\n",
    "plt.title(\"Box Plot of Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4cc011",
   "metadata": {},
   "source": [
    "Above Box plot shows that Prices below log 6.43 and above 12.44 are outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecfea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax1.set_title('Figure 2: Box Plot of Odometer')\n",
    "ax1.boxplot(cars['odometer'], vert=False, flierprops=red_square)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ebab99",
   "metadata": {},
   "source": [
    "Above box plot shows that Odometer rating anything below -107725.0 and above 282235.0 are outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d81cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2)=plt.subplots(ncols=2,figsize=(12,5))\n",
    "\n",
    "#ploting boxplot\n",
    "o1, o2 = outliers_range(cars,'year')\n",
    "ax1.boxplot(sorted(cars['year']), vert=False, flierprops=red_square)\n",
    "ax1.set_xlabel(\"Years\")\n",
    "ax1.set_title(\"Figure 3: Box Plot of Year\")\n",
    "ax1.text(o1-8,1.05,str(round(o1,2)))\n",
    "\n",
    "#ploting histogram\n",
    "hist,bins=np.histogram(cars['year'])\n",
    "n, bins, patches = ax2.hist(x=cars['year'], bins=bins)\n",
    "ax2.set_xlabel(\"Years\")\n",
    "ax2.set_title(\"Figure 4: Histogram of Year\")\n",
    "for i in range(len(n)):\n",
    "    if(n[i]>2000):\n",
    "        ax2.text(bins[i],n[i]+3000,str(n[i]))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c648e8b8",
   "metadata": {},
   "source": [
    "\n",
    "Above box plot shows that anything below 1995 and above 2022 are outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32313329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing outliers using outliers_range() funciton on logprice, odometer and year columns\n",
    "cars_new = cars.copy()\n",
    "out = np.array([\n",
    "    'logprice',\n",
    "    'odometer',\n",
    "    'year'\n",
    "])\n",
    "for col in out:\n",
    "    o1,o2 = outliers_range(cars_new, col)\n",
    "    cars_new = cars_new[(cars_new[col]>=o1) & (cars_new[col]<=o2)]\n",
    "    print('IQR of',col,'=',o1,o2)\n",
    "cars_new = cars_new[cars_new['price']!=0]\n",
    "cars_new.drop('logprice',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a342e759",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape before process={cars.shape}\")\n",
    "print(f\"Shape After process={cars_new.shape}\")\n",
    "print(\n",
    "    f\"Total {cars.shape[0]-cars_new.shape[0]} rows \"\n",
    "    f\"and {cars.shape[1]-cars_new.shape[1]} columns were removed\")\n",
    "cars_new.to_csv(\"vehicles_finalized.csv\",index=False)\n",
    "\n",
    "cars_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dde028",
   "metadata": {},
   "source": [
    "Summarizing the Data Cleanup Steps:\n",
    "\n",
    "Column Removal:\n",
    "\n",
    "    We removed the \"VIN\" column since it didn't provide any valuable information for price prediction. Additionally, the \"state\" column was dropped as it duplicated information already present in the \"region\" column.\n",
    "\n",
    "Handling Missing Values:\n",
    "\n",
    "    To address missing values in categorical columns, we employed several regression estimators like BayesianRidge, DecisionTreeRegressor, ExtraTreesRegressor, and KNeighboursRegressor. After evaluating their performance, BayesianRidge yielded the lowest Mean Squared Error (MSE), and we used it to impute missing values in categorical columns.\n",
    "\n",
    "Outlier Detection and Removal:\n",
    "\n",
    "    Outliers were identified in the \"Price,\" \"Odometer,\" and \"Year\" columns using the Interquartile Range (IQR) method.\n",
    "    A total of 62,427 rows were removed during the outlier removal process for these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a3c018",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_cleaned = cars_new.copy()\n",
    "cars_cleaned['year'] = cars_cleaned['year'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eafa890",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bbfcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_cleaned.columns\n",
    "\n",
    "cars_sample = cars_cleaned.sample(1000)\n",
    "cars_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa34288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a pairplot to view distribution of numerical features.\n",
    "colors = iter([\n",
    "    'xkcd:red purple', 'xkcd:pale teal', 'xkcd:warm purple',\n",
    "    'xkcd:light forest green', 'xkcd:blue with a hint of purple',\n",
    "    'xkcd:light peach', 'xkcd:dusky purple', 'xkcd:pale mauve',\n",
    "    'xkcd:bright sky blue'])\n",
    "\n",
    "def my_scatter(x,y, **kwargs):\n",
    "    kwargs['color'] = next(colors)\n",
    "    plt.scatter(x,y, **kwargs)\n",
    "\n",
    "def my_hist(x, **kwargs):\n",
    "    kwargs['color'] = next(colors)\n",
    "    plt.hist(x, **kwargs)\n",
    "\n",
    "g = sns.PairGrid(cars_sample)\n",
    "g.map_diag(my_hist)\n",
    "g.map_offdiag(my_scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a765400",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(cars_cleaned, x=\"price\", nbins=20, title=\"Price histogram\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51a6b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def barplot_generator(df=pd.DataFrame(), x='', y='', title='', hue=''):\n",
    "    \"\"\"\n",
    "    Function which take df, x, y, title and hue as input\n",
    "    and generates a bar plot using seaborn.barplot.\n",
    "    \"\"\"\n",
    "    fig, axis=plt.subplots()\n",
    "    if hue:\n",
    "        fig.set_size_inches(10, 6)\n",
    "        sns.barplot(x=x, y=y, data=df, ax=axis, hue=hue)\n",
    "    else:\n",
    "        fig.set_size_inches(10, 6)\n",
    "        sns.barplot(x=x, y=y, data=df, ax=axis)\n",
    "    axis.set_title(title)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd25f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_generator(cars_cleaned, 'fuel', 'price', 'Car price by Fuel Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773cf5f2",
   "metadata": {},
   "source": [
    "\n",
    "Hybrid cars have lower price. Diesel cars cost more than electric ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b05f5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_generator(cars_cleaned, 'fuel', 'price', 'Car price by Fuel Type with condition as hue', hue='condition')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d003dd9f",
   "metadata": {},
   "source": [
    "\n",
    "Irrespective of fuel type, Car condition decides the car prices. Salvaged cars have lower price point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a86d0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_generator(cars_cleaned, 'year', 'price', 'Car price by Year')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e478b9",
   "metadata": {},
   "source": [
    "\n",
    "Car prices are ever increasing starting 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a6a64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_generator(cars_cleaned, 'condition', 'price', 'Car price by Condition', hue='size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a132ddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_generator(cars_cleaned, 'transmission', 'price', 'Car price by Transmission')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8129d5ee",
   "metadata": {},
   "source": [
    "\n",
    "The above 2 plots clearly shows that car condition drives the car price. Size of car impacts the prices as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccdd05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_generator(cars_cleaned, 'type', 'price', 'Car price by Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b6b999",
   "metadata": {},
   "source": [
    "\n",
    "Manual car prices are low. Other types transmission have higher prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbfc9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_generator(cars_cleaned, 'manufacturer', 'price', 'Car price by manufacturer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32db4e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_generator(cars_cleaned, 'size', 'price', 'Car price by Size')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ce3696",
   "metadata": {},
   "source": [
    "Moving forward with modeling:\n",
    "\n",
    "Now that we have our nearly finalized dataset, it's time to construct a variety of regression models with the target variable being \"price.\" During this modeling phase, we will consider different model types and explore various parameters. Additionally, we will conduct cross-validation to validate our model findings and ensure their robustness.\n",
    "\n",
    "If you have any specific questions or need guidance on particular aspects of the modeling process, feel free to share, and I'll be happy to assist further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6315442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['year','odometer']\n",
    "cat_features = [\n",
    "    'manufacturer',\n",
    "    'model',\n",
    "    'condition',\n",
    "    'cylinders',\n",
    "    'fuel',\n",
    "    'title_status',\n",
    "    'transmission',\n",
    "    'drive',\n",
    "    'size',\n",
    "    'type',\n",
    "    'paint_color'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfa38a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "cars_cleaned[cat_features] = cars_cleaned[cat_features].apply(\n",
    "    label_encoder.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2ea161",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c97713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling numerical data\n",
    "norm = StandardScaler()\n",
    "cars_cleaned['price'] = np.log(cars_cleaned['price'])\n",
    "cars_cleaned['odometer'] = norm.fit_transform(np.array(cars_cleaned['odometer']).reshape(-1,1))\n",
    "cars_cleaned['year'] = norm.fit_transform(np.array(cars_cleaned['year']).reshape(-1,1))\n",
    "cars_cleaned['model'] = norm.fit_transform(np.array(cars_cleaned['model']).reshape(-1,1))\n",
    "\n",
    "# Scaling target variable\n",
    "q1, q3 = (cars_cleaned['price'].quantile([0.25,0.75]))\n",
    "o1 = q1-1.5*(q3-q1)\n",
    "o2 = q3+1.5*(q3-q1)\n",
    "cars_cleaned = cars_cleaned[(cars_cleaned.price>=o1) & (cars_cleaned.price<=o2)]\n",
    "\n",
    "cars_cleaned.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02acae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df, n):\n",
    "    \"\"\"\n",
    "    Function to split training and test dataset\n",
    "    \"\"\"\n",
    "    X = df.iloc[:,n]\n",
    "    y = df.iloc[:,-1:].values.T\n",
    "    y = y[0]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        train_size=0.9,\n",
    "        test_size=0.1,\n",
    "        random_state=0\n",
    "    )\n",
    "    return (X_train,X_test,y_train,y_test)\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_dataset(\n",
    "    cars_cleaned,\n",
    "    list(range(len(list(cars_cleaned.columns))-1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a7c303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_neg(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    Function to remove negative values predicted by models.\n",
    "    \"\"\"\n",
    "    index_ = [index for index in range(len(y_pred)) if(y_pred[index]>0)]\n",
    "    y_pred = y_pred[index_]\n",
    "    y_test = y_test[index_]\n",
    "    y_pred[y_pred<0]\n",
    "    return (y_test,y_pred)\n",
    "\n",
    "def evaluate(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    Function to evalute the model\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    result.append(mean_squared_log_error(y_test, y_pred))\n",
    "    result.append(np.sqrt(result[0]))\n",
    "    result.append(r2_score(y_test,y_pred))\n",
    "    result.append(round(r2_score(y_test,y_pred)*100,4))\n",
    "    return (result)\n",
    "\n",
    "# Dataframe to store the performance of each model\n",
    "# Using MSLE since we have applied logarithmic to price target variable.\n",
    "accuracy = pd.DataFrame(index=['MSLE', 'Root MSLE', 'R2 Score','Accuracy(%)'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b02e4b",
   "metadata": {},
   "source": [
    "\n",
    "Linear regression with RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921a368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('feature_selection', RFE(LinearRegression())),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "# Define hyperparameters\n",
    "hyper_params = {\n",
    "    'feature_selection__n_features_to_select': list(range(1, 14))\n",
    "}\n",
    "\n",
    "# Create KFold cross-validator\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=100)\n",
    "\n",
    "# Perform GridSearchCV\n",
    "model_cv = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=hyper_params,\n",
    "    scoring='r2',\n",
    "    cv=folds,\n",
    "    verbose=1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model_cv.fit(X_train, y_train)\n",
    "\n",
    "# Get CV results\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a108bc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = 10**np.linspace(10, -2, 400)\n",
    "\n",
    "# Initialize RidgeCV with the alphas\n",
    "ridge_cv = RidgeCV(alphas=alphas, store_cv_values=True)\n",
    "\n",
    "# Fit RidgeCV to your data\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "# Get the cross-validated mean squared errors for each alpha\n",
    "cv_mean_errors = np.mean(ridge_cv.cv_values_, axis=0)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogx(alphas, cv_mean_errors, '-o', color='b', markersize=5, label='Mean CV MSE')\n",
    "plt.xlabel('Alpha (Regularization Strength)')\n",
    "plt.ylabel('Mean CV MSE')\n",
    "plt.title('Alpha Selection for Ridge Regression')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Print the best alpha\n",
    "best_alpha = ridge_cv.alpha_\n",
    "print(f\"Best alpha: {best_alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094a0cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of alpha values to test\n",
    "alphas = 10**np.linspace(10, -2, 400)\n",
    "\n",
    "# Initialize LassoCV with the alphas\n",
    "lasso_cv = LassoCV(alphas=alphas)\n",
    "\n",
    "# Fit LassoCV to your data\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "\n",
    "# Get the best alpha\n",
    "best_alpha = lasso_cv.alpha_\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogx(alphas, lasso_cv.mse_path_, ':')\n",
    "plt.plot(alphas, lasso_cv.mse_path_.mean(axis=-1), 'k', label='Average across the folds', linewidth=2)\n",
    "plt.axvline(best_alpha, linestyle='--', color='k', label='Best alpha')\n",
    "plt.legend()\n",
    "plt.xlabel('Alpha (Regularization Strength)')\n",
    "plt.ylabel('Mean Square Error (MSE)')\n",
    "plt.title('Alpha Selection for Lasso Regression')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Best alpha: {best_alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dd5b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model object and fitting it\n",
    "lasso_model = Lasso(alpha=0.010)\n",
    "lasso_model.fit(X_train,y_train)\n",
    "y_pred = lasso_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4ff5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating error/accuracy\n",
    "\n",
    "y_test_3, y_pred_3 = remove_neg(\n",
    "    y_test,\n",
    "    y_pred\n",
    ")\n",
    "r3_lasso = evaluate(y_test_3,y_pred_3)\n",
    "\n",
    "print(f\"MSLE : {r3_lasso[0]}\")\n",
    "print(f\"Root MSLE : {r3_lasso[1]}\")\n",
    "print(f\"R2 Score : {r3_lasso[2]} or {r3_lasso[3]}%\")\n",
    "\n",
    "accuracy['Lasso Regression'] = r3_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eda7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x=y_test, y=y_pred, labels={'x': \"Actual Car Price\", 'y': \"Predicted Car Price\"}, title=\"Lasso Model: Used Car Prediction with Log price\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64f621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x=np.exp(y_test), y=np.exp(y_pred), labels={'x': \"Actual Car Price\", 'y': \"Predicted Car Price\"}, title=\"Lasso Model: Used Car Prediction with Actual price\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382727c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(x=X_train.columns, y=lasso_model.coef_, title=\"Lasso Model Coefs\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22c60e4",
   "metadata": {},
   "source": [
    "Recommendations to Car Dealership:\n",
    "\n",
    "Based on our analysis, here are some key recommendations that car dealerships can use to optimize their used car inventory and drive sales while ensuring customer satisfaction:\n",
    "\n",
    "    Prioritize Year and Odometer: Consumers highly value the year of manufacture and odometer reading, which significantly influence the price range of a car. Focus on offering cars with favorable year and mileage attributes to attract more buyers.\n",
    "\n",
    "    Consider Diesel and Electric Cars: Diesel and electric vehicles tend to command higher prices compared to gasoline cars. Expanding the inventory with these options can help increase overall revenue.\n",
    "\n",
    "    Emphasize High Cylinder Counts: Cars with more cylinders tend to have higher price points. Consider offering cars with higher cylinder counts to cater to customers looking for performance-oriented vehicles.\n",
    "\n",
    "    Monitor Title Status and Condition: Be mindful of the title status and condition of the cars in your inventory. Salvaged cars can significantly reduce prices, so it's essential to properly assess and price them accordingly.\n",
    "\n",
    "    Diversify Transmission Types: Different transmission types impact car prices differently. Automatic and other transmission types typically have higher price points, while manual transmissions tend to lower the car's price. Diversify your inventory to cater to various preferences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82edea41",
   "metadata": {},
   "source": [
    "def predict_car_price(year, odometer, manufacturer, condition, cylinders, fuel, transmission, drive, size, type, paint_color, model):\n",
    "    \"\"\"\n",
    "    Predicts the price of a used car.\n",
    "\n",
    "    Args:\n",
    "        year (int): Year of the car (1995 to 2022).\n",
    "        odometer (int): Mileage of the car (integer greater than 0).\n",
    "        manufacturer (str): Car manufacturer.\n",
    "        condition (str): Car condition.\n",
    "        cylinders (str): Number of cylinders in the car.\n",
    "        fuel (str): Type of fuel used.\n",
    "        transmission (str): Type of transmission.\n",
    "        drive (str): Drive type.\n",
    "        size (str): Car size.\n",
    "        type (str): Car type.\n",
    "        paint_color (str): Car paint color.\n",
    "        model (str): Car model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bf4f1a",
   "metadata": {},
   "source": [
    "Deployment:\n",
    "\n",
    "Having finalized our models and findings, it's time to convey this information effectively to our client. We will present our work in the form of a concise report that highlights our primary discoveries. It's important to remember that our audience consists of used car dealers who are keen to fine-tune their inventory strategies.\n",
    "\n",
    "Addressing the Needs of Used Car Dealers:\n",
    "\n",
    "As a used car dealership, understanding what consumers value in a used car is crucial. Leveraging the data you've provided, we've diligently grouped and analyzed it to offer valuable insights aimed at enhancing customer conversion rates. Our analysis has illuminated key factors that predict customer interest in purchasing a car, including:\n",
    "\n",
    "    The car's manufacturing year.\n",
    "    The car's size.\n",
    "    The car's condition.\n",
    "\n",
    "Our findings underscore that a recently manufactured car in good condition tends to outperform older, poorly maintained vehicles in terms of sales.\n",
    "\n",
    "Future Endeavors:\n",
    "\n",
    "While this analysis provides a solid foundation for comprehending customer behavior, it hasn't revealed any groundbreaking insights. To delve deeper into this realm, we would like to conduct further analyses. This entails addressing data gaps, such as:\n",
    "\n",
    "    Obtaining purchase and selling prices for cars.\n",
    "    Identifying the manufacturing year and the year in which the car was sold.\n",
    "    Rectifying missing or incorrect values, such as rows with both odometer and price values set to 0, clarifying if an odometer value of 0 signifies a new car, and filling missing data for model and manufacturer using a VIN database if available.\n",
    "    Investigating the root causes of outliers within the data.\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "At this juncture, it's evident that additional data is necessary to provide a definitive recommendation. While our analysis has been insightful, it remains inconclusive. We look forward to further exploring the data to provide more comprehensive guidance in the future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
